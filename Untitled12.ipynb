{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, subset):\n",
        "        self.dataset = SPEECHCOMMANDS(root=\".\", download=True, subset=subset)\n",
        "\n",
        "        self.audio_transforms = torchaudio.transforms.MFCC(\n",
        "            sample_rate=16000,\n",
        "            n_mfcc=40\n",
        "        )\n",
        "\n",
        "        self.labels = sorted(list(set(datapoint[2] for datapoint in self.dataset)))\n",
        "        self.label_to_index = {label: index for index, label in enumerate(self.labels)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        waveform, sample_rate, label, _, _ = self.dataset[idx]\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfcc = self.audio_transforms(waveform)\n",
        "\n",
        "        # Get label index\n",
        "        label_index = self.label_to_index[label]\n",
        "\n",
        "        return mfcc, label_index\n",
        "\n",
        "# 2. Model Architecture\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, time, features)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out[:, -1, :])  # Take the last time step\n",
        "        return output\n",
        "\n",
        "# 3. Training Function\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# 4. Evaluation Function\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            total_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    return total_loss / len(test_loader), correct / len(test_loader.dataset)\n",
        "\n",
        "# 5. Main Training Loop\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    input_dim = 40  # MFCC features\n",
        "    hidden_dim = 256\n",
        "    learning_rate = 0.001\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create dataset and dataloaders\n",
        "    try:\n",
        "        train_dataset = SpeechDataset(\"training\")\n",
        "        test_dataset = SpeechDataset(\"testing\")\n",
        "\n",
        "        num_classes = len(train_dataset.labels)\n",
        "        output_dim = num_classes\n",
        "\n",
        "        print(f\"Number of classes: {num_classes}\")\n",
        "        print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "        print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Initialize model\n",
        "    model = SpeechRecognitionModel(input_dim, hidden_dim, output_dim).to(device)\n",
        "    print(model)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    # Training loop\n",
        "    try:\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "            test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            test_losses.append(test_loss)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "            print(f'Train Loss: {train_loss:.4f}')\n",
        "            print(f'Test Loss: {test_loss:.4f}')\n",
        "            print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Plotting results\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(test_losses, label='Test Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(accuracies)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting results: {str(e)}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daPNVsbcdK6z",
        "outputId": "c62eb371-4567-49bb-aea7-43eb83e949b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.26G/2.26G [00:28<00:00, 86.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 35\n",
            "Number of training samples: 84843\n",
            "Number of test samples: 11005\n",
            "SpeechRecognitionModel(\n",
            "  (lstm): LSTM(40, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=35, bias=True)\n",
            ")\n",
            "Error during training: LSTM: Expected input to be 2D or 3D, got 4D instead\n"
          ]
        }
      ]
    }
  ]
}